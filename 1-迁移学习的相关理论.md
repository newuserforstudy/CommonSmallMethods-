## 迁移学习的相关理论

## 1 迁移学习的概念

- 迁移学习:运用已存有的知识对**不同但相关领域问题**进行求解的一种新的机器学习方法.它**放宽了**传统机器学习中的两个基本假设:(1) 用于学习的训练样本与新的测试样本满足独立同分布的条件;(2) 必须有足够可利用的训练样本才能学习得到一个好的分类模型.目的是迁移已有的知识来解决目标领域中仅有少量有标签样本数据甚至没有的学习问题.

## 2 迁移学习的问题研究

- 什么条件下从源领域数据训练出的分类器能够在目标领域表现出优异的分类性能,即什么条件下可进行迁移?
- 给定无标注目标领域,或者有少量的标记数据,如何在训练过程中与大量有标记的源数据结合使得测试时的误差最小,即迁移学习算法的研究.

## 3 预训练模型

- 预训练模型，顾名思义，就是先在大量通用语料上训练模型，也就是不仅模型结构定义好了，而且模型参数已经通过大量训练数据学习好了。这些模型通常都是被验证比较有效的模型,然后再针对性地具体任务进行迁移训练.

## 4 使用pytorch 进行迁移学习的基本方法

- 冻结参数
- 修改网络 
- fine-tuning

```python
from torchvision.models import alexnet
import torch.nn as nn
import torch.optim as optim

if __name__ == '__main__':
    model = alexnet(pretrained=True)
    print(model)
    for param in model.parameters():
        param.requires_grad = False
    
    model.classifier = nn.Linear(4096, 2)
    for param in model.classifier.parameters():
        param.requires_grad = True

    optim.Adam(model.classifier.parameters(), lr=0.001)
```

